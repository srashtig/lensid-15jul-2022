{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-02 13:12:38.680287: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2021-09-02 13:12:38.680317: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from lensid.utils.ml_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = 'train'\n",
    "\n",
    "#data_dir = '../../data/qts/'  #ALICE\n",
    "\n",
    "#df_dir='../../data/dataframes/train/' ##alice\n",
    "df_dir = '/home/srashti.goyal/strong-lensing-ml/data/dataframes/' #CIT\n",
    "\n",
    "data_dir = '/home/srashti.goyal/alice_data_lensid/qts/' + indir + '/' ##CIT\n",
    "\n",
    "odir='dense_out/alice/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lensed = pd.read_csv(df_dir+str(indir)+'/lensed.csv' )\n",
    "df_lensed=df_lensed.drop(columns=['Unnamed: 0'])\n",
    "df_lensed['img_0']=df_lensed['img_0'].values \n",
    "df_lensed['img_1']=df_lensed['img_1'].values \n",
    "df_lensed=df_lensed[:1400]\n",
    "df_unlensed = pd.read_csv(df_dir+str(indir)+'/unlensed_half.csv' )\n",
    "df_unlensed=df_unlensed.drop(columns=['Unnamed: 0'])\n",
    "df_unlensed = df_unlensed.sample(frac = 1,random_state = 42).reset_index(drop = True)[:1400]\n",
    "df_train = pd.concat([df_lensed,df_unlensed],ignore_index = True)\n",
    "df_train=df_train.sample(frac = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_0</th>\n",
       "      <th>img_1</th>\n",
       "      <th>Lensing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>70</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>207</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>104</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>141</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>79</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     img_0 img_1  Lensing\n",
       "2795    70   318        0\n",
       "2796   207   209        0\n",
       "2797   104   125        0\n",
       "2798   141   284        0\n",
       "2799    79   293        0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input feature matrix for Detector H1 from the Qtransforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "det='H1'\n",
    "X , y,missing_ids, df_train =  generate_resize_densenet_fm(df_train).DenseNet_input_matrix(det = det,data_mode_dense=\"current\",data_dir=data_dir,phenom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_0</th>\n",
       "      <th>img_1</th>\n",
       "      <th>Lensing</th>\n",
       "      <th>mean_overlap_qts_H1</th>\n",
       "      <th>std_overlap_qts_H1</th>\n",
       "      <th>lsq_overlap_qts_H1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>968_img_0</td>\n",
       "      <td>968_img_1</td>\n",
       "      <td>1</td>\n",
       "      <td>7976.941406</td>\n",
       "      <td>0.114142</td>\n",
       "      <td>4561.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>16</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>7171.079590</td>\n",
       "      <td>0.103907</td>\n",
       "      <td>5348.660156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>301</td>\n",
       "      <td>418</td>\n",
       "      <td>0</td>\n",
       "      <td>7165.990723</td>\n",
       "      <td>0.107025</td>\n",
       "      <td>4880.691895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>997_img_0</td>\n",
       "      <td>997_img_1</td>\n",
       "      <td>1</td>\n",
       "      <td>6744.811035</td>\n",
       "      <td>0.106766</td>\n",
       "      <td>4340.098633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>66_img_0</td>\n",
       "      <td>66_img_1</td>\n",
       "      <td>1</td>\n",
       "      <td>6895.767090</td>\n",
       "      <td>0.110302</td>\n",
       "      <td>4164.415039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          img_0      img_1  Lensing  mean_overlap_qts_H1  std_overlap_qts_H1  \\\n",
       "2795  968_img_0  968_img_1        1          7976.941406            0.114142   \n",
       "2796         16        219        0          7171.079590            0.103907   \n",
       "2797        301        418        0          7165.990723            0.107025   \n",
       "2798  997_img_0  997_img_1        1          6744.811035            0.106766   \n",
       "2799   66_img_0   66_img_1        1          6895.767090            0.110302   \n",
       "\n",
       "      lsq_overlap_qts_H1  \n",
       "2795         4561.007812  \n",
       "2796         5348.660156  \n",
       "2797         4880.691895  \n",
       "2798         4340.098633  \n",
       "2799         4164.415039  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dense_model_trained = train_densenet(X,y,det,20, 0.01) #20,0.01, .005\n",
    "dense_model_trained.save(odir+'det+'.h5')## Train and save the Densenet model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Functional)     (None, 4, 4, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               491776    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 18,814,017\n",
      "Trainable params: 18,584,961\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 5.6682 - accuracy: 0.6893\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.59643, saving model to trained_densenet201_det_H1.h5\n",
      "70/70 [==============================] - 170s 2s/step - loss: 5.6682 - accuracy: 0.6893 - val_loss: 5.6596 - val_accuracy: 0.5964\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1.8000000000000004e-05.\n",
      "Epoch 2/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 5.2188 - accuracy: 0.8759\n",
      "Epoch 00002: val_accuracy did not improve from 0.59643\n",
      "70/70 [==============================] - 161s 2s/step - loss: 5.2188 - accuracy: 0.8759 - val_loss: 5.4447 - val_accuracy: 0.5375\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 2.6000000000000002e-05.\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.7876 - accuracy: 0.9621\n",
      "Epoch 00003: val_accuracy did not improve from 0.59643\n",
      "70/70 [==============================] - 159s 2s/step - loss: 4.7876 - accuracy: 0.9621 - val_loss: 5.1099 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 3.4000000000000007e-05.\n",
      "Epoch 4/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.3609 - accuracy: 0.9897\n",
      "Epoch 00004: val_accuracy improved from 0.59643 to 0.66250, saving model to trained_densenet201_det_H1.h5\n",
      "70/70 [==============================] - 160s 2s/step - loss: 4.3609 - accuracy: 0.9897 - val_loss: 4.6819 - val_accuracy: 0.6625\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.9159 - accuracy: 0.9991\n",
      "Epoch 00005: val_accuracy improved from 0.66250 to 0.71250, saving model to trained_densenet201_det_H1.h5\n",
      "70/70 [==============================] - 159s 2s/step - loss: 3.9159 - accuracy: 0.9991 - val_loss: 4.2195 - val_accuracy: 0.7125\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 5e-05.\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.4807 - accuracy: 0.9991\n",
      "Epoch 00006: val_accuracy improved from 0.71250 to 0.78214, saving model to trained_densenet201_det_H1.h5\n",
      "70/70 [==============================] - 159s 2s/step - loss: 3.4807 - accuracy: 0.9991 - val_loss: 3.7362 - val_accuracy: 0.7821\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.0942 - accuracy: 0.9996\n",
      "Epoch 00007: val_accuracy improved from 0.78214 to 0.80000, saving model to trained_densenet201_det_H1.h5\n",
      "70/70 [==============================] - 159s 2s/step - loss: 3.0942 - accuracy: 0.9996 - val_loss: 3.4027 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 3.5600000000000005e-05.\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.8053 - accuracy: 1.0000\n",
      "Epoch 00008: val_accuracy improved from 0.80000 to 0.81071, saving model to trained_densenet201_det_H1.h5\n",
      "70/70 [==============================] - 157s 2s/step - loss: 2.8053 - accuracy: 1.0000 - val_loss: 3.1678 - val_accuracy: 0.8107\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 3.0480000000000006e-05.\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.5832 - accuracy: 0.9996\n",
      "Epoch 00009: val_accuracy improved from 0.81071 to 0.82679, saving model to trained_densenet201_det_H1.h5\n",
      "70/70 [==============================] - 160s 2s/step - loss: 2.5832 - accuracy: 0.9996 - val_loss: 3.0075 - val_accuracy: 0.8268\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 2.6384000000000004e-05.\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.4026 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy improved from 0.82679 to 0.83393, saving model to trained_densenet201_det_H1.h5\n",
      "70/70 [==============================] - 163s 2s/step - loss: 2.4026 - accuracy: 1.0000 - val_loss: 2.8620 - val_accuracy: 0.8339\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 2.3107200000000005e-05.\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.2542 - accuracy: 1.0000\n",
      "Epoch 00011: val_accuracy improved from 0.83393 to 0.84107, saving model to trained_densenet201_det_H1.h5\n",
      "70/70 [==============================] - 157s 2s/step - loss: 2.2542 - accuracy: 1.0000 - val_loss: 2.7295 - val_accuracy: 0.8411\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 2.0485760000000004e-05.\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.1306 - accuracy: 1.0000\n",
      "Epoch 00012: val_accuracy improved from 0.84107 to 0.85536, saving model to trained_densenet201_det_H1.h5\n",
      "70/70 [==============================] - 158s 2s/step - loss: 2.1306 - accuracy: 1.0000 - val_loss: 2.6121 - val_accuracy: 0.8554\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1.8388608000000004e-05.\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.0238 - accuracy: 1.0000\n",
      "Epoch 00013: val_accuracy improved from 0.85536 to 0.85714, saving model to trained_densenet201_det_H1.h5\n",
      "70/70 [==============================] - 156s 2s/step - loss: 2.0238 - accuracy: 1.0000 - val_loss: 2.5240 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1.6710886400000004e-05.\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.9317 - accuracy: 1.0000\n",
      "Epoch 00014: val_accuracy did not improve from 0.85714\n",
      "70/70 [==============================] - 157s 2s/step - loss: 1.9317 - accuracy: 1.0000 - val_loss: 2.4403 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1.5368709120000003e-05.\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.8491 - accuracy: 1.0000\n",
      "Epoch 00015: val_accuracy did not improve from 0.85714\n",
      "70/70 [==============================] - 156s 2s/step - loss: 1.8491 - accuracy: 1.0000 - val_loss: 2.3710 - val_accuracy: 0.8464\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1.4294967296000005e-05.\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.7749 - accuracy: 1.0000\n",
      "Epoch 00016: val_accuracy did not improve from 0.85714\n",
      "70/70 [==============================] - 157s 2s/step - loss: 1.7749 - accuracy: 1.0000 - val_loss: 2.3037 - val_accuracy: 0.8464\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1.3435973836800004e-05.\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.7073 - accuracy: 1.0000\n",
      "Epoch 00017: val_accuracy did not improve from 0.85714\n",
      "70/70 [==============================] - 151s 2s/step - loss: 1.7073 - accuracy: 1.0000 - val_loss: 2.2534 - val_accuracy: 0.8518\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.2748779069440003e-05.\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.6447 - accuracy: 1.0000\n",
      "Epoch 00018: val_accuracy did not improve from 0.85714\n",
      "70/70 [==============================] - 151s 2s/step - loss: 1.6447 - accuracy: 1.0000 - val_loss: 2.1946 - val_accuracy: 0.8536\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.2199023255552003e-05.\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.5867 - accuracy: 1.0000\n",
      "Epoch 00019: val_accuracy did not improve from 0.85714\n",
      "70/70 [==============================] - 151s 2s/step - loss: 1.5867 - accuracy: 1.0000 - val_loss: 2.1337 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.1759218604441602e-05.\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.5326 - accuracy: 1.0000\n",
      "Epoch 00020: val_accuracy did not improve from 0.85714\n",
      "70/70 [==============================] - 151s 2s/step - loss: 1.5326 - accuracy: 1.0000 - val_loss: 2.0899 - val_accuracy: 0.8518\n",
      "Time Taken:  3215.769932746887\n"
     ]
    }
   ],
   "source": [
    "dense_model_trained = train_densenet(X,y,det,20, 0.01) #20,0.01, .005\n",
    "dense_model_trained.save(odir+det+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Det L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del y\n",
    "det='L1'\n",
    "X , y,missing_ids, df_train =  generate_resize_densenet_fm(df_train).DenseNet_input_matrix(det = det,data_mode_dense=\"current\",data_dir=data_dir,phenom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Functional)     (None, 4, 4, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               491776    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 18,814,017\n",
      "Trainable params: 18,584,961\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 5.5973 - accuracy: 0.7277\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.46786, saving model to trained_densenet201_det_L1.h5\n",
      "70/70 [==============================] - 154s 2s/step - loss: 5.5973 - accuracy: 0.7277 - val_loss: 5.7410 - val_accuracy: 0.4679\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1.8000000000000004e-05.\n",
      "Epoch 2/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 5.1738 - accuracy: 0.8835\n",
      "Epoch 00002: val_accuracy did not improve from 0.46786\n",
      "70/70 [==============================] - 149s 2s/step - loss: 5.1738 - accuracy: 0.8835 - val_loss: 5.5835 - val_accuracy: 0.4661\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 2.6000000000000002e-05.\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.7614 - accuracy: 0.9629\n",
      "Epoch 00003: val_accuracy improved from 0.46786 to 0.48036, saving model to trained_densenet201_det_L1.h5\n",
      "70/70 [==============================] - 150s 2s/step - loss: 4.7614 - accuracy: 0.9629 - val_loss: 5.2879 - val_accuracy: 0.4804\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 3.4000000000000007e-05.\n",
      "Epoch 4/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.3279 - accuracy: 0.9951\n",
      "Epoch 00004: val_accuracy improved from 0.48036 to 0.56071, saving model to trained_densenet201_det_L1.h5\n",
      "70/70 [==============================] - 151s 2s/step - loss: 4.3279 - accuracy: 0.9951 - val_loss: 4.7931 - val_accuracy: 0.5607\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.8965 - accuracy: 0.9996\n",
      "Epoch 00005: val_accuracy improved from 0.56071 to 0.60714, saving model to trained_densenet201_det_L1.h5\n",
      "70/70 [==============================] - 151s 2s/step - loss: 3.8965 - accuracy: 0.9996 - val_loss: 4.3434 - val_accuracy: 0.6071\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 5e-05.\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.4521 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy improved from 0.60714 to 0.76786, saving model to trained_densenet201_det_L1.h5\n",
      "70/70 [==============================] - 152s 2s/step - loss: 3.4521 - accuracy: 1.0000 - val_loss: 3.7277 - val_accuracy: 0.7679\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.0652 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy improved from 0.76786 to 0.81607, saving model to trained_densenet201_det_L1.h5\n",
      "70/70 [==============================] - 151s 2s/step - loss: 3.0652 - accuracy: 1.0000 - val_loss: 3.3694 - val_accuracy: 0.8161\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 3.5600000000000005e-05.\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.7761 - accuracy: 1.0000\n",
      "Epoch 00008: val_accuracy improved from 0.81607 to 0.82321, saving model to trained_densenet201_det_L1.h5\n",
      "70/70 [==============================] - 151s 2s/step - loss: 2.7761 - accuracy: 1.0000 - val_loss: 3.1430 - val_accuracy: 0.8232\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 3.0480000000000006e-05.\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.5515 - accuracy: 0.9996\n",
      "Epoch 00009: val_accuracy improved from 0.82321 to 0.83929, saving model to trained_densenet201_det_L1.h5\n",
      "70/70 [==============================] - 151s 2s/step - loss: 2.5515 - accuracy: 0.9996 - val_loss: 2.9517 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 2.6384000000000004e-05.\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.3698 - accuracy: 0.9996\n",
      "Epoch 00010: val_accuracy did not improve from 0.83929\n",
      "70/70 [==============================] - 148s 2s/step - loss: 2.3698 - accuracy: 0.9996 - val_loss: 2.8039 - val_accuracy: 0.8375\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 2.3107200000000005e-05.\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.2220 - accuracy: 1.0000\n",
      "Epoch 00011: val_accuracy did not improve from 0.83929\n",
      "70/70 [==============================] - 148s 2s/step - loss: 2.2220 - accuracy: 1.0000 - val_loss: 2.6852 - val_accuracy: 0.8357\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 2.0485760000000004e-05.\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.0958 - accuracy: 1.0000\n",
      "Epoch 00012: val_accuracy improved from 0.83929 to 0.85000, saving model to trained_densenet201_det_L1.h5\n",
      "70/70 [==============================] - 151s 2s/step - loss: 2.0958 - accuracy: 1.0000 - val_loss: 2.5861 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1.8388608000000004e-05.\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.9897 - accuracy: 1.0000\n",
      "Epoch 00013: val_accuracy did not improve from 0.85000\n",
      "70/70 [==============================] - 149s 2s/step - loss: 1.9897 - accuracy: 1.0000 - val_loss: 2.4961 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1.6710886400000004e-05.\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.8960 - accuracy: 1.0000\n",
      "Epoch 00014: val_accuracy improved from 0.85000 to 0.85536, saving model to trained_densenet201_det_L1.h5\n",
      "70/70 [==============================] - 150s 2s/step - loss: 1.8960 - accuracy: 1.0000 - val_loss: 2.4326 - val_accuracy: 0.8554\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1.5368709120000003e-05.\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.8135 - accuracy: 1.0000\n",
      "Epoch 00015: val_accuracy did not improve from 0.85536\n",
      "70/70 [==============================] - 148s 2s/step - loss: 1.8135 - accuracy: 1.0000 - val_loss: 2.3630 - val_accuracy: 0.8446\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1.4294967296000005e-05.\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.7386 - accuracy: 1.0000\n",
      "Epoch 00016: val_accuracy did not improve from 0.85536\n",
      "70/70 [==============================] - 147s 2s/step - loss: 1.7386 - accuracy: 1.0000 - val_loss: 2.3057 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1.3435973836800004e-05.\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.6705 - accuracy: 1.0000\n",
      "Epoch 00017: val_accuracy did not improve from 0.85536\n",
      "70/70 [==============================] - 147s 2s/step - loss: 1.6705 - accuracy: 1.0000 - val_loss: 2.2429 - val_accuracy: 0.8554\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.2748779069440003e-05.\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.6070 - accuracy: 1.0000\n",
      "Epoch 00018: val_accuracy did not improve from 0.85536\n",
      "70/70 [==============================] - 148s 2s/step - loss: 1.6070 - accuracy: 1.0000 - val_loss: 2.1778 - val_accuracy: 0.8536\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.2199023255552003e-05.\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.5485 - accuracy: 1.0000\n",
      "Epoch 00019: val_accuracy did not improve from 0.85536\n",
      "70/70 [==============================] - 147s 2s/step - loss: 1.5485 - accuracy: 1.0000 - val_loss: 2.1182 - val_accuracy: 0.8536\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.1759218604441602e-05.\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.4928 - accuracy: 1.0000\n",
      "Epoch 00020: val_accuracy did not improve from 0.85536\n",
      "70/70 [==============================] - 148s 2s/step - loss: 1.4928 - accuracy: 1.0000 - val_loss: 2.0643 - val_accuracy: 0.8554\n",
      "Time Taken:  3052.4179842472076\n"
     ]
    }
   ],
   "source": [
    "dense_model_trained = train_densenet(X,y,det,20, 0.01)  \n",
    "dense_model_trained.save(odir+det+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Det V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del y\n",
    "det='V1'\n",
    "X , y,missing_ids, df_train =  generate_resize_densenet_fm(df_train).DenseNet_input_matrix(det = det,data_mode_dense=\"current\",data_dir=data_dir,phenom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Functional)     (None, 4, 4, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               491776    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 18,814,017\n",
      "Trainable params: 18,584,961\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 5.6497 - accuracy: 0.6888\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.47857, saving model to trained_densenet201_det_V1.h5\n",
      "70/70 [==============================] - 153s 2s/step - loss: 5.6497 - accuracy: 0.6888 - val_loss: 5.6971 - val_accuracy: 0.4786\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1.8000000000000004e-05.\n",
      "Epoch 2/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 5.2283 - accuracy: 0.8674\n",
      "Epoch 00002: val_accuracy improved from 0.47857 to 0.54821, saving model to trained_densenet201_det_V1.h5\n",
      "70/70 [==============================] - 149s 2s/step - loss: 5.2283 - accuracy: 0.8674 - val_loss: 5.4349 - val_accuracy: 0.5482\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 2.6000000000000002e-05.\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.7978 - accuracy: 0.9536\n",
      "Epoch 00003: val_accuracy improved from 0.54821 to 0.57143, saving model to trained_densenet201_det_V1.h5\n",
      "70/70 [==============================] - 150s 2s/step - loss: 4.7978 - accuracy: 0.9536 - val_loss: 5.1149 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 3.4000000000000007e-05.\n",
      "Epoch 4/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.3530 - accuracy: 0.9893\n",
      "Epoch 00004: val_accuracy improved from 0.57143 to 0.66607, saving model to trained_densenet201_det_V1.h5\n",
      "70/70 [==============================] - 150s 2s/step - loss: 4.3530 - accuracy: 0.9893 - val_loss: 4.6685 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.9144 - accuracy: 0.9982\n",
      "Epoch 00005: val_accuracy improved from 0.66607 to 0.73929, saving model to trained_densenet201_det_V1.h5\n",
      "70/70 [==============================] - 151s 2s/step - loss: 3.9144 - accuracy: 0.9982 - val_loss: 4.1887 - val_accuracy: 0.7393\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 5e-05.\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.4616 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy improved from 0.73929 to 0.80179, saving model to trained_densenet201_det_V1.h5\n",
      "70/70 [==============================] - 150s 2s/step - loss: 3.4616 - accuracy: 1.0000 - val_loss: 3.6906 - val_accuracy: 0.8018\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.0772 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy improved from 0.80179 to 0.82857, saving model to trained_densenet201_det_V1.h5\n",
      "70/70 [==============================] - 151s 2s/step - loss: 3.0772 - accuracy: 1.0000 - val_loss: 3.3542 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 3.5600000000000005e-05.\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.7869 - accuracy: 1.0000\n",
      "Epoch 00008: val_accuracy improved from 0.82857 to 0.84286, saving model to trained_densenet201_det_V1.h5\n",
      "70/70 [==============================] - 152s 2s/step - loss: 2.7869 - accuracy: 1.0000 - val_loss: 3.1277 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 3.0480000000000006e-05.\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.5645 - accuracy: 0.9996\n",
      "Epoch 00009: val_accuracy did not improve from 0.84286\n",
      "70/70 [==============================] - 148s 2s/step - loss: 2.5645 - accuracy: 0.9996 - val_loss: 2.9563 - val_accuracy: 0.8375\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 2.6384000000000004e-05.\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.3833 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy did not improve from 0.84286\n",
      "70/70 [==============================] - 147s 2s/step - loss: 2.3833 - accuracy: 1.0000 - val_loss: 2.8351 - val_accuracy: 0.8411\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 2.3107200000000005e-05.\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.2337 - accuracy: 1.0000\n",
      "Epoch 00011: val_accuracy did not improve from 0.84286\n",
      "70/70 [==============================] - 147s 2s/step - loss: 2.2337 - accuracy: 1.0000 - val_loss: 2.7296 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 2.0485760000000004e-05.\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.1103 - accuracy: 1.0000\n",
      "Epoch 00012: val_accuracy did not improve from 0.84286\n",
      "70/70 [==============================] - 146s 2s/step - loss: 2.1103 - accuracy: 1.0000 - val_loss: 2.6273 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1.8388608000000004e-05.\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.0029 - accuracy: 1.0000\n",
      "Epoch 00013: val_accuracy did not improve from 0.84286\n",
      "70/70 [==============================] - 147s 2s/step - loss: 2.0029 - accuracy: 1.0000 - val_loss: 2.5409 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1.6710886400000004e-05.\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.9095 - accuracy: 1.0000\n",
      "Epoch 00014: val_accuracy improved from 0.84286 to 0.84821, saving model to trained_densenet201_det_V1.h5\n",
      "70/70 [==============================] - 150s 2s/step - loss: 1.9095 - accuracy: 1.0000 - val_loss: 2.4581 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1.5368709120000003e-05.\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.8277 - accuracy: 1.0000\n",
      "Epoch 00015: val_accuracy did not improve from 0.84821\n",
      "70/70 [==============================] - 147s 2s/step - loss: 1.8277 - accuracy: 1.0000 - val_loss: 2.3887 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1.4294967296000005e-05.\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.7529 - accuracy: 1.0000\n",
      "Epoch 00016: val_accuracy did not improve from 0.84821\n",
      "70/70 [==============================] - 147s 2s/step - loss: 1.7529 - accuracy: 1.0000 - val_loss: 2.3155 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1.3435973836800004e-05.\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.6845 - accuracy: 1.0000\n",
      "Epoch 00017: val_accuracy did not improve from 0.84821\n",
      "70/70 [==============================] - 148s 2s/step - loss: 1.6845 - accuracy: 1.0000 - val_loss: 2.2588 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.2748779069440003e-05.\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.6217 - accuracy: 1.0000\n",
      "Epoch 00018: val_accuracy did not improve from 0.84821\n",
      "70/70 [==============================] - 148s 2s/step - loss: 1.6217 - accuracy: 1.0000 - val_loss: 2.2091 - val_accuracy: 0.8375\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.2199023255552003e-05.\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.5632 - accuracy: 1.0000\n",
      "Epoch 00019: val_accuracy did not improve from 0.84821\n",
      "70/70 [==============================] - 147s 2s/step - loss: 1.5632 - accuracy: 1.0000 - val_loss: 2.1431 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.1759218604441602e-05.\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.5077 - accuracy: 1.0000\n",
      "Epoch 00020: val_accuracy did not improve from 0.84821\n",
      "70/70 [==============================] - 148s 2s/step - loss: 1.5077 - accuracy: 1.0000 - val_loss: 2.0936 - val_accuracy: 0.8446\n",
      "Time Taken:  3039.1292448043823\n"
     ]
    }
   ],
   "source": [
    "dense_model_trained = train_densenet(X,y,det,20, 0.01) #20,0.01, .005\n",
    "dense_model_trained.save(odir+det+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
