{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from ML_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = 'train'\n",
    "data_dir = '../../data/qts/'+str(indir)+'/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lensed = pd.read_csv('../../data/dataframes/'+str(indir)+'/lensed.csv' )\n",
    "df_lensed=df_lensed.drop(columns=['Unnamed: 0'])\n",
    "df_lensed['img_0']=df_lensed['img_0'].values \n",
    "df_lensed['img_1']=df_lensed['img_1'].values \n",
    "df_lensed=df_lensed[:2400]\n",
    "df_unlensed = pd.read_csv('../../data/dataframes/'+str(indir)+'/unlensed_half.csv' )\n",
    "df_unlensed=df_unlensed.drop(columns=['Unnamed: 0'])\n",
    "df_unlensed = df_unlensed.sample(frac = 1,random_state = 42).reset_index(drop = True)[:2400]\n",
    "df_train = pd.concat([df_lensed,df_unlensed],ignore_index = True)\n",
    "df_train=df_train.sample(frac = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_0</th>\n",
       "      <th>img_1</th>\n",
       "      <th>Lensing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>56</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>32</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>111_img_0</td>\n",
       "      <td>111_img_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>1073_img_0</td>\n",
       "      <td>1073_img_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>187</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           img_0       img_1  Lensing\n",
       "4795          56         333        0\n",
       "4796          32         140        0\n",
       "4797   111_img_0   111_img_1        1\n",
       "4798  1073_img_0  1073_img_1        1\n",
       "4799         187         225        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "det='H1'\n",
    "X , y,missing_ids, df_train =  generate_resize_densenet_fm(df_train).DenseNet_input_matrix(det = det,data_mode_dense=\"current\",data_dir=data_dir,phenom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_0</th>\n",
       "      <th>img_1</th>\n",
       "      <th>Lensing</th>\n",
       "      <th>mean_overlap_qts_H1</th>\n",
       "      <th>std_overlap_qts_H1</th>\n",
       "      <th>lsq_overlap_qts_H1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>56</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>6457.521973</td>\n",
       "      <td>0.099783</td>\n",
       "      <td>5512.762695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>32</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>6693.517578</td>\n",
       "      <td>0.104566</td>\n",
       "      <td>4085.177734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>111_img_0</td>\n",
       "      <td>111_img_1</td>\n",
       "      <td>1</td>\n",
       "      <td>6700.125488</td>\n",
       "      <td>0.112489</td>\n",
       "      <td>3918.588867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>1073_img_0</td>\n",
       "      <td>1073_img_1</td>\n",
       "      <td>1</td>\n",
       "      <td>7428.762695</td>\n",
       "      <td>0.110943</td>\n",
       "      <td>4886.513672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>187</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>6690.597656</td>\n",
       "      <td>0.101651</td>\n",
       "      <td>5564.596680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           img_0       img_1  Lensing  mean_overlap_qts_H1  \\\n",
       "4795          56         333        0          6457.521973   \n",
       "4796          32         140        0          6693.517578   \n",
       "4797   111_img_0   111_img_1        1          6700.125488   \n",
       "4798  1073_img_0  1073_img_1        1          7428.762695   \n",
       "4799         187         225        0          6690.597656   \n",
       "\n",
       "      std_overlap_qts_H1  lsq_overlap_qts_H1  \n",
       "4795            0.099783         5512.762695  \n",
       "4796            0.104566         4085.177734  \n",
       "4797            0.112489         3918.588867  \n",
       "4798            0.110943         4886.513672  \n",
       "4799            0.101651         5564.596680  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Functional)     (None, 4, 4, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               491776    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 18,814,017\n",
      "Trainable params: 18,584,961\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 3.0247 - accuracy: 0.7581\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.59062, saving model to trained_densenet201_det_H1.h5\n",
      "120/120 [==============================] - 292s 2s/step - loss: 3.0247 - accuracy: 0.7581 - val_loss: 3.1294 - val_accuracy: 0.5906\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1.8000000000000004e-05.\n",
      "Epoch 2/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 2.6665 - accuracy: 0.8883\n",
      "Epoch 00002: val_accuracy improved from 0.59062 to 0.71875, saving model to trained_densenet201_det_H1.h5\n",
      "120/120 [==============================] - 282s 2s/step - loss: 2.6665 - accuracy: 0.8883 - val_loss: 2.8618 - val_accuracy: 0.7188\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 2.6000000000000002e-05.\n",
      "Epoch 3/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 2.3250 - accuracy: 0.9578\n",
      "Epoch 00003: val_accuracy improved from 0.71875 to 0.78125, saving model to trained_densenet201_det_H1.h5\n",
      "120/120 [==============================] - 285s 2s/step - loss: 2.3250 - accuracy: 0.9578 - val_loss: 2.5453 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 3.4000000000000007e-05.\n",
      "Epoch 4/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9912 - accuracy: 0.9927\n",
      "Epoch 00004: val_accuracy improved from 0.78125 to 0.83438, saving model to trained_densenet201_det_H1.h5\n",
      "120/120 [==============================] - 324s 3s/step - loss: 1.9912 - accuracy: 0.9927 - val_loss: 2.2173 - val_accuracy: 0.8344\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "Epoch 5/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.6993 - accuracy: 0.9997\n",
      "Epoch 00005: val_accuracy improved from 0.83438 to 0.84271, saving model to trained_densenet201_det_H1.h5\n",
      "120/120 [==============================] - 394s 3s/step - loss: 1.6993 - accuracy: 0.9997 - val_loss: 1.9966 - val_accuracy: 0.8427\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 5e-05.\n",
      "Epoch 6/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.4323 - accuracy: 0.9997\n",
      "Epoch 00006: val_accuracy improved from 0.84271 to 0.87500, saving model to trained_densenet201_det_H1.h5\n",
      "120/120 [==============================] - 277s 2s/step - loss: 1.4323 - accuracy: 0.9997 - val_loss: 1.7168 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "Epoch 7/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.2204 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy did not improve from 0.87500\n",
      "120/120 [==============================] - 292s 2s/step - loss: 1.2204 - accuracy: 1.0000 - val_loss: 1.6403 - val_accuracy: 0.8687\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 3.5600000000000005e-05.\n",
      "Epoch 8/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.0746 - accuracy: 0.9997\n",
      "Epoch 00008: val_accuracy did not improve from 0.87500\n",
      "120/120 [==============================] - 275s 2s/step - loss: 1.0746 - accuracy: 0.9997 - val_loss: 1.5181 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 3.0480000000000006e-05.\n",
      "Epoch 9/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9678 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy did not improve from 0.87500\n",
      "120/120 [==============================] - 275s 2s/step - loss: 0.9678 - accuracy: 1.0000 - val_loss: 1.4520 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 2.6384000000000004e-05.\n",
      "Epoch 10/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8863 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy did not improve from 0.87500\n",
      "120/120 [==============================] - 273s 2s/step - loss: 0.8863 - accuracy: 1.0000 - val_loss: 1.3777 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 2.3107200000000005e-05.\n",
      "Epoch 11/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8190 - accuracy: 0.9997\n",
      "Epoch 00011: val_accuracy did not improve from 0.87500\n",
      "120/120 [==============================] - 277s 2s/step - loss: 0.8190 - accuracy: 0.9997 - val_loss: 1.2928 - val_accuracy: 0.8677\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 2.0485760000000004e-05.\n",
      "Epoch 12/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7662 - accuracy: 0.9995\n",
      "Epoch 00012: val_accuracy did not improve from 0.87500\n",
      "120/120 [==============================] - 274s 2s/step - loss: 0.7662 - accuracy: 0.9995 - val_loss: 1.2430 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1.8388608000000004e-05.\n",
      "Epoch 13/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7200 - accuracy: 1.0000\n",
      "Epoch 00013: val_accuracy did not improve from 0.87500\n",
      "120/120 [==============================] - 272s 2s/step - loss: 0.7200 - accuracy: 1.0000 - val_loss: 1.2245 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1.6710886400000004e-05.\n",
      "Epoch 14/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6817 - accuracy: 0.9997\n",
      "Epoch 00014: val_accuracy did not improve from 0.87500\n",
      "120/120 [==============================] - 276s 2s/step - loss: 0.6817 - accuracy: 0.9997 - val_loss: 1.2085 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1.5368709120000003e-05.\n",
      "Epoch 15/15\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6474 - accuracy: 1.0000\n",
      "Epoch 00015: val_accuracy did not improve from 0.87500\n",
      "120/120 [==============================] - 276s 2s/step - loss: 0.6474 - accuracy: 1.0000 - val_loss: 1.1842 - val_accuracy: 0.8729\n",
      "Time Taken:  4395.299542188644\n"
     ]
    }
   ],
   "source": [
    "dense_model_trained = train_densenet(X,y,det,15, 0.005) #20,0.01, .005\n",
    "dense_model_trained.save('1-dense_model_trained_'+det+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del y\n",
    "det='L1'\n",
    "X , y,missing_ids, df_train =  generate_resize_densenet_fm(df_train).DenseNet_input_matrix(det = det,data_mode_dense=\"current\",data_dir=data_dir,phenom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Functional)     (None, 4, 4, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               491776    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 18,814,017\n",
      "Trainable params: 18,584,961\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 5.5451 - accuracy: 0.7344\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65104, saving model to trained_densenet201_det_L1.h5\n",
      "120/120 [==============================] - 281s 2s/step - loss: 5.5451 - accuracy: 0.7344 - val_loss: 5.5316 - val_accuracy: 0.6510\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1.8000000000000004e-05.\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 5.0100 - accuracy: 0.8724\n",
      "Epoch 00002: val_accuracy improved from 0.65104 to 0.71667, saving model to trained_densenet201_det_L1.h5\n",
      "120/120 [==============================] - 277s 2s/step - loss: 5.0100 - accuracy: 0.8724 - val_loss: 5.0932 - val_accuracy: 0.7167\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 2.6000000000000002e-05.\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 4.4193 - accuracy: 0.9487\n",
      "Epoch 00003: val_accuracy improved from 0.71667 to 0.76562, saving model to trained_densenet201_det_L1.h5\n",
      "120/120 [==============================] - 276s 2s/step - loss: 4.4193 - accuracy: 0.9487 - val_loss: 4.5324 - val_accuracy: 0.7656\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 3.4000000000000007e-05.\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 3.7899 - accuracy: 0.9911\n",
      "Epoch 00004: val_accuracy improved from 0.76562 to 0.80313, saving model to trained_densenet201_det_L1.h5\n",
      "120/120 [==============================] - 282s 2s/step - loss: 3.7899 - accuracy: 0.9911 - val_loss: 3.8939 - val_accuracy: 0.8031\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 3.1761 - accuracy: 0.9982\n",
      "Epoch 00005: val_accuracy improved from 0.80313 to 0.82500, saving model to trained_densenet201_det_L1.h5\n",
      "120/120 [==============================] - 282s 2s/step - loss: 3.1761 - accuracy: 0.9982 - val_loss: 3.2926 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 5e-05.\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 2.5939 - accuracy: 0.9995\n",
      "Epoch 00006: val_accuracy improved from 0.82500 to 0.84167, saving model to trained_densenet201_det_L1.h5\n",
      "120/120 [==============================] - 279s 2s/step - loss: 2.5939 - accuracy: 0.9995 - val_loss: 2.7648 - val_accuracy: 0.8417\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 2.1379 - accuracy: 0.9974\n",
      "Epoch 00007: val_accuracy improved from 0.84167 to 0.85833, saving model to trained_densenet201_det_L1.h5\n",
      "120/120 [==============================] - 276s 2s/step - loss: 2.1379 - accuracy: 0.9974 - val_loss: 2.3995 - val_accuracy: 0.8583\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 3.5600000000000005e-05.\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8149 - accuracy: 0.9979\n",
      "Epoch 00008: val_accuracy did not improve from 0.85833\n",
      "120/120 [==============================] - 279s 2s/step - loss: 1.8149 - accuracy: 0.9979 - val_loss: 2.2092 - val_accuracy: 0.8531\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 3.0480000000000006e-05.\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.5769 - accuracy: 0.9995\n",
      "Epoch 00009: val_accuracy improved from 0.85833 to 0.86563, saving model to trained_densenet201_det_L1.h5\n",
      "120/120 [==============================] - 283s 2s/step - loss: 1.5769 - accuracy: 0.9995 - val_loss: 1.9823 - val_accuracy: 0.8656\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 2.6384000000000004e-05.\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.4000 - accuracy: 0.9995\n",
      "Epoch 00010: val_accuracy did not improve from 0.86563\n",
      "120/120 [==============================] - 283s 2s/step - loss: 1.4000 - accuracy: 0.9995 - val_loss: 1.8688 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 2.3107200000000005e-05.\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.2623 - accuracy: 0.9987\n",
      "Epoch 00011: val_accuracy improved from 0.86563 to 0.86979, saving model to trained_densenet201_det_L1.h5\n",
      "120/120 [==============================] - 275s 2s/step - loss: 1.2623 - accuracy: 0.9987 - val_loss: 1.7265 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 2.0485760000000004e-05.\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.1486 - accuracy: 0.9990\n",
      "Epoch 00012: val_accuracy did not improve from 0.86979\n",
      "120/120 [==============================] - 273s 2s/step - loss: 1.1486 - accuracy: 0.9990 - val_loss: 1.6524 - val_accuracy: 0.8552\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1.8388608000000004e-05.\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.0544 - accuracy: 0.9992\n",
      "Epoch 00013: val_accuracy did not improve from 0.86979\n",
      "120/120 [==============================] - 272s 2s/step - loss: 1.0544 - accuracy: 0.9992 - val_loss: 1.5697 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1.6710886400000004e-05.\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9747 - accuracy: 0.9995\n",
      "Epoch 00014: val_accuracy did not improve from 0.86979\n",
      "120/120 [==============================] - 285s 2s/step - loss: 0.9747 - accuracy: 0.9995 - val_loss: 1.5083 - val_accuracy: 0.8687\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1.5368709120000003e-05.\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9066 - accuracy: 0.9997\n",
      "Epoch 00015: val_accuracy did not improve from 0.86979\n",
      "120/120 [==============================] - 276s 2s/step - loss: 0.9066 - accuracy: 0.9997 - val_loss: 1.4334 - val_accuracy: 0.8573\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1.4294967296000005e-05.\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8457 - accuracy: 0.9997\n",
      "Epoch 00016: val_accuracy improved from 0.86979 to 0.87083, saving model to trained_densenet201_det_L1.h5\n",
      "120/120 [==============================] - 278s 2s/step - loss: 0.8457 - accuracy: 0.9997 - val_loss: 1.3953 - val_accuracy: 0.8708\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1.3435973836800004e-05.\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7927 - accuracy: 0.9995\n",
      "Epoch 00017: val_accuracy did not improve from 0.87083\n",
      "120/120 [==============================] - 279s 2s/step - loss: 0.7927 - accuracy: 0.9995 - val_loss: 1.3290 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.2748779069440003e-05.\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7449 - accuracy: 0.9995\n",
      "Epoch 00018: val_accuracy did not improve from 0.87083\n",
      "120/120 [==============================] - 279s 2s/step - loss: 0.7449 - accuracy: 0.9995 - val_loss: 1.2942 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.2199023255552003e-05.\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6990 - accuracy: 1.0000\n",
      "Epoch 00019: val_accuracy did not improve from 0.87083\n",
      "120/120 [==============================] - 272s 2s/step - loss: 0.6990 - accuracy: 1.0000 - val_loss: 1.2686 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.1759218604441602e-05.\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6596 - accuracy: 0.9992\n",
      "Epoch 00020: val_accuracy did not improve from 0.87083\n",
      "120/120 [==============================] - 278s 2s/step - loss: 0.6596 - accuracy: 0.9992 - val_loss: 1.2318 - val_accuracy: 0.8646\n",
      "Time Taken:  5630.586702823639\n"
     ]
    }
   ],
   "source": [
    "dense_model_trained = train_densenet(X,y,det,20, 0.01)  \n",
    "dense_model_trained.save('1-dense_model_trained_'+det+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del y\n",
    "det='V1'\n",
    "X , y,missing_ids, df_train =  generate_resize_densenet_fm(df_train).DenseNet_input_matrix(det = det,data_mode_dense=\"current\",data_dir=data_dir,phenom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Functional)     (None, 4, 4, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               491776    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 18,814,017\n",
      "Trainable params: 18,584,961\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 5.5681 - accuracy: 0.7424\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67604, saving model to trained_densenet201_det_V1.h5\n",
      "120/120 [==============================] - 277s 2s/step - loss: 5.5681 - accuracy: 0.7424 - val_loss: 5.5392 - val_accuracy: 0.6760\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 1.8000000000000004e-05.\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 5.0485 - accuracy: 0.8708\n",
      "Epoch 00002: val_accuracy improved from 0.67604 to 0.73229, saving model to trained_densenet201_det_V1.h5\n",
      "120/120 [==============================] - 294s 2s/step - loss: 5.0485 - accuracy: 0.8708 - val_loss: 5.1086 - val_accuracy: 0.7323\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 2.6000000000000002e-05.\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 4.4620 - accuracy: 0.9526\n",
      "Epoch 00003: val_accuracy did not improve from 0.73229\n",
      "120/120 [==============================] - 269s 2s/step - loss: 4.4620 - accuracy: 0.9526 - val_loss: 4.7161 - val_accuracy: 0.6417\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 3.4000000000000007e-05.\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 3.8582 - accuracy: 0.9893\n",
      "Epoch 00004: val_accuracy did not improve from 0.73229\n",
      "120/120 [==============================] - 271s 2s/step - loss: 3.8582 - accuracy: 0.9893 - val_loss: 4.1713 - val_accuracy: 0.7104\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 3.2622 - accuracy: 0.9992\n",
      "Epoch 00005: val_accuracy improved from 0.73229 to 0.79792, saving model to trained_densenet201_det_V1.h5\n",
      "120/120 [==============================] - 270s 2s/step - loss: 3.2622 - accuracy: 0.9992 - val_loss: 3.5309 - val_accuracy: 0.7979\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 5e-05.\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 2.7025 - accuracy: 0.9990\n",
      "Epoch 00006: val_accuracy improved from 0.79792 to 0.84167, saving model to trained_densenet201_det_V1.h5\n",
      "120/120 [==============================] - 270s 2s/step - loss: 2.7025 - accuracy: 0.9990 - val_loss: 2.9654 - val_accuracy: 0.8417\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 4.2000000000000004e-05.\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 2.2491 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy improved from 0.84167 to 0.85625, saving model to trained_densenet201_det_V1.h5\n",
      "120/120 [==============================] - 271s 2s/step - loss: 2.2491 - accuracy: 1.0000 - val_loss: 2.6656 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 3.5600000000000005e-05.\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.9332 - accuracy: 0.9992\n",
      "Epoch 00008: val_accuracy did not improve from 0.85625\n",
      "120/120 [==============================] - 276s 2s/step - loss: 1.9332 - accuracy: 0.9992 - val_loss: 2.3794 - val_accuracy: 0.8469\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 3.0480000000000006e-05.\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.6998 - accuracy: 0.9997\n",
      "Epoch 00009: val_accuracy did not improve from 0.85625\n",
      "120/120 [==============================] - 271s 2s/step - loss: 1.6998 - accuracy: 0.9997 - val_loss: 2.2710 - val_accuracy: 0.8490\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 2.6384000000000004e-05.\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.5222 - accuracy: 0.9987\n",
      "Epoch 00010: val_accuracy did not improve from 0.85625\n",
      "120/120 [==============================] - 268s 2s/step - loss: 1.5222 - accuracy: 0.9987 - val_loss: 2.0993 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 2.3107200000000005e-05.\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.3807 - accuracy: 0.9992\n",
      "Epoch 00011: val_accuracy did not improve from 0.85625\n",
      "120/120 [==============================] - 275s 2s/step - loss: 1.3807 - accuracy: 0.9992 - val_loss: 1.9503 - val_accuracy: 0.8552\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 2.0485760000000004e-05.\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.2651 - accuracy: 0.9995\n",
      "Epoch 00012: val_accuracy improved from 0.85625 to 0.85938, saving model to trained_densenet201_det_V1.h5\n",
      "120/120 [==============================] - 279s 2s/step - loss: 1.2651 - accuracy: 0.9995 - val_loss: 1.8436 - val_accuracy: 0.8594\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1.8388608000000004e-05.\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.1677 - accuracy: 1.0000\n",
      "Epoch 00013: val_accuracy did not improve from 0.85938\n",
      "120/120 [==============================] - 278s 2s/step - loss: 1.1677 - accuracy: 1.0000 - val_loss: 1.7533 - val_accuracy: 0.8552\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1.6710886400000004e-05.\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.0851 - accuracy: 1.0000\n",
      "Epoch 00014: val_accuracy did not improve from 0.85938\n",
      "120/120 [==============================] - 270s 2s/step - loss: 1.0851 - accuracy: 1.0000 - val_loss: 1.7072 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1.5368709120000003e-05.\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.0134 - accuracy: 1.0000\n",
      "Epoch 00015: val_accuracy did not improve from 0.85938\n",
      "120/120 [==============================] - 271s 2s/step - loss: 1.0134 - accuracy: 1.0000 - val_loss: 1.6402 - val_accuracy: 0.8531\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1.4294967296000005e-05.\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9503 - accuracy: 1.0000\n",
      "Epoch 00016: val_accuracy improved from 0.85938 to 0.86042, saving model to trained_densenet201_det_V1.h5\n",
      "120/120 [==============================] - 276s 2s/step - loss: 0.9503 - accuracy: 1.0000 - val_loss: 1.5758 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1.3435973836800004e-05.\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8923 - accuracy: 1.0000\n",
      "Epoch 00017: val_accuracy did not improve from 0.86042\n",
      "120/120 [==============================] - 268s 2s/step - loss: 0.8923 - accuracy: 1.0000 - val_loss: 1.5318 - val_accuracy: 0.8542\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.2748779069440003e-05.\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8411 - accuracy: 0.9992\n",
      "Epoch 00018: val_accuracy did not improve from 0.86042\n",
      "120/120 [==============================] - 269s 2s/step - loss: 0.8411 - accuracy: 0.9992 - val_loss: 1.5043 - val_accuracy: 0.8510\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.2199023255552003e-05.\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7919 - accuracy: 1.0000\n",
      "Epoch 00019: val_accuracy did not improve from 0.86042\n",
      "120/120 [==============================] - 275s 2s/step - loss: 0.7919 - accuracy: 1.0000 - val_loss: 1.4589 - val_accuracy: 0.8490\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.1759218604441602e-05.\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7470 - accuracy: 1.0000\n",
      "Epoch 00020: val_accuracy did not improve from 0.86042\n",
      "120/120 [==============================] - 270s 2s/step - loss: 0.7470 - accuracy: 1.0000 - val_loss: 1.4133 - val_accuracy: 0.8510\n",
      "Time Taken:  5530.21373295784\n"
     ]
    }
   ],
   "source": [
    "dense_model_trained = train_densenet(X,y,det,20, 0.01) #20,0.01, .005\n",
    "dense_model_trained.save('1-dense_model_trained_'+det+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
